#import "TorchModule.h"
#import <LibTorch/LibTorch.h>

@implementation TorchModule {
 @protected
  torch::jit::script::Module _impl;
}

- (nullable instancetype)initWithFileAtPath:(NSString*)filePath {
  self = [super init];
  if (self) {
    try {
      auto qengines = at::globalContext().supportedQEngines();
      if (std::find(qengines.begin(), qengines.end(), at::QEngine::QNNPACK) != qengines.end()) {
        at::globalContext().setQEngine(at::QEngine::QNNPACK);
      }
      _impl = torch::jit::load(filePath.UTF8String);
      _impl.eval();
    } catch (const std::exception& exception) {
      NSLog(@"%s", exception.what());
      return nil;
    }
  }
  return self;
}


- (NSArray<NSNumber*>*)predictImage:(void*)imageBuffer {
  try {

      at::Tensor tensor = torch::from_blob(imageBuffer, {51, 32}, at::kFloat).transpose(1, 0).unsqueeze(0);
//    at::Tensor tensor = torch::from_blob(imageBuffer, {16000}, at::kFloat).unsqueeze(0);
//      at::Tensor tensor = torch::ones({1, 16000});
//    tensor -= (tensor.mean(0) + 1e-8);
//    tensor /= ((tensor.pow(2).sum(0)/40).sqrt() + 1e-8);   // mean-scaling first does not change the standard deviation.
//    tensor = tensor.reshape({1, -1, 40});
    torch::autograd::AutoGradMode guard(false);
    at::AutoNonVariableTypeMode non_var_type_mode(true);
    auto outputTensor = _impl.forward({tensor}).toTensor();
    float* floatBuffer = outputTensor.data_ptr<float>();
    if (!floatBuffer) {
      return nil;
    }
    NSMutableArray* results = [[NSMutableArray alloc] init];
    for (int i = 0; i < 30; i++) {
      [results addObject:@(floatBuffer[i])];
    }
    return [results copy];
  } catch (const std::exception& exception) {
    NSLog(@"%s", exception.what());
  }
  return nil;
}

@end


